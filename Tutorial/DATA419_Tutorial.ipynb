{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial - My Instagram Network\n",
    "<strong>Contents:</strong>\n",
    "1. Introduction\n",
    "2. Methodology\n",
    "3. Data Collection\n",
    "4. Network Analysis\n",
    "5. Graph Customization\n",
    "6. Legal and Ethical Consideration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction\n",
    "Visualizing our Instagram networking is an exciting thing, but many are restrained because Instagram does not provide sufficient API, unlike other social media do. To address it, an operational, concise, easy-to-understand building process for Instagram networks will be introduced. It includes scraping profiles of followers or followings, analysing network structure, and network visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "<ul>\n",
    "<li><strong>Instagram data scraping:</strong> A open source instagram data scraper is used. The tool was developed in 2019 by a Data Science student, MaximPiessen, in Belgium. Instead of calling API, it uses Selenium WebDriver.</li>\n",
    "<li><strong>Network data analysis and visualization:</strong> <a href=\"https://networkx.org\">Networkx</a>, a Python package, is used to reveal the charateristics of networks and visualizing network structures. Networkx uses Matplotlib as the data visualization library.</li>\n",
    "</ul>\n",
    "<strong>Steps:</strong><br>\n",
    "To analyse one's social network, one's follower list is obtained first, then for each follower, their following list is obtained, next in the following list find the accounts that are also in the one's follower list. Through this process, find the relationships of all one's followers.<br>\n",
    "<img src=\"Methodology.png\"></img><br>\n",
    "As a student of Network Science, after analysing the real Instagram social network, we will be able to have a good understanding of online communities and social networks.\n",
    "In a word, in the end of the tutorial, you will learn a scraper tool, an approach to quantify and qualify networks, and a couple of techniques to beautify network graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "Instagram only provides very few API endpoints for retrieving data, so a variety of web scrapers developed by data scientists are used for the Instagram data collection. An easy-to-use scraper, developed in Python by MaximPiessen, is introduced for our data collection and can be accessed on https://github.com/MaximPiessen/instagram_network_analysis. A bit of modification has been made to be run better in the local environment and to meet the requirement of the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step One: Download and run scraper\n",
    "The scraping code can be downloaded from<br>\n",
    "https://github.com/JiaAnthonyLi/DATA419/tree/main/Tutorial/Code of scraper.\n",
    "<br>\n",
    "<ul>\n",
    "<li>bot.py: scraping class</li>\n",
    "<li>get_my_followers.py: call scraping class to get one's all follwers and generate 'my_followers.txt'</li>\n",
    "<li>get_relations.py: call scraping class to get the relations of one's all followers, and generate 'relations.txt'</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step Two: Get my followers\n",
    "Run 'my_followers.py' in terminal.<br>\n",
    "$python get_my_followers.py --username {your_IG_username} --password {your_IG_password}\n",
    "\n",
    "Notice:\n",
    "1. Use your Instagram username and password to replace the ones in the example.\n",
    "2. During the scraping, a new chrome will be opened and please make it at least partially visible otherwise often the server does not respond requests.\n",
    "3. If Instagram blocks requests too many times and the running gets stuck, you can stop the process and re-start. (To be updated) \n",
    "\n",
    "Result:\n",
    "'my_followers.txt' is generated and each line represents a follower link.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step Three: Get relations of followers\n",
    "Run 'get_relations.py' in terminal.\n",
    "$python get_relations.py --username {your_IG_username}  --password {your_IG_password} --relations_file relations.txt\n",
    "\n",
    "Notice:\n",
    "Besides the three points to notice in step two.\n",
    "1. The name of the generated file can be customized by the argument '--relations_file'. For example, modify to 'my_relations.txt'.\n",
    "2. 'start_profile.txt' is used to save the last scraped follower's index. You can modify it and skip the follower that has thousands of followings to avoid scraping taking months. And by the file, no need to redo all scraping that has been done, if manually stopping and restarting in the last run.\n",
    "3. The scraping may take a few days or weeks since one person normally has over 100 followers or followings.\n",
    "\n",
    "Result:\n",
    "'relations.txt' is generated and each line represents a link (relation) from a follower to a followed account.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Analysis\n",
    "Now, it is the time to use the file generated in the last section. The file is the input of the entire analysis. No matter whether you have succeeded to generate your own 'relations.txt' or not, we provide an example file 'my_relations.txt' for the demonstration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get a glance at the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file\n",
    "G = nx.read_edgelist('https://github.com/JiaAnthonyLi/DATA419/blob/main/Tutorial/my_relations.txt', \n",
    "                        nodetype=str, \n",
    "                        create_using=nx.DiGraph())\n",
    "# The summary of the graph\n",
    "print(nx.info(G))\n",
    "# Draw the graph\n",
    "nx.draw(G, with_labels=True, node_color='red', node_size=100, edge_color='blue', font_color='black', font_size=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Neighbours\n",
    "In the Instagram network, successors represent followed persons, and predecessors represent followers. To find the successors and predecessors of one node (one person) in the network, we need to call DiGraph.predecessors() and DiGraph.successors()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Successors of diane_channe:', list(G.successors(\"diane_channe\")))\n",
    "print('Predecessors of diane_channe:', list(G.predecessors(\"diane_channe\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the code above, we will see the all followers and followings of 'diane_channe'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Density\n",
    "Density shows how dense (sparse) a network is. To calculate it, divide the actual edge number in the network by the possible maximum number of edges. Networkx provides density() to output the statistic directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.density(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Degree\n",
    "Further, we can find the network's 'average in-degree' or 'average out-degree', 'degree distribution', and 'average shortest path length'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average in-degree and out-degree of the network. In theory, they are the same.\n",
    "print('Average degree: {}'.format(G.number_of_edges() / G.number_of_nodes()))\n",
    "\n",
    "# Plot the degree distribution.\n",
    "degrees = [G.degree(n) for n in G.nodes()]\n",
    "plt.hist(degrees)\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Degree Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Calculate the average shortest path length.\n",
    "nx.average_shortest_path_length(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a power law distribution of degrees. Most people have few links, while a few people have a larger number of relations.\n",
    "Additionally, an exception is thrown if the network is directed and is not weakly connected. Use the code below to check the network attribute: is_weakly_connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.is_weakly_connected(G) # To check if the network is weakly connected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Centrality\n",
    "Centrality is a measurement to estimate the importance of a node. In practice, there are three ways to figure out centrality. They are betweenness centrality, closeness centrality, and degree centrality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <li>Betweenness centrality:</li>\n",
    "'Betweenness centrality' can be used to measure the importance of nodes when a diffusion process occurs in a network. In this case, the transmission of 'meme' can be a diffusion process.\n",
    "One manifestation of 'betweenness centrality' is that the more the shortest paths by which a node is crossed, the higher the betweenness centrality of the node is. Networkx provides the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betweenness = nx.centrality.betweenness_centrality(G)   # Return the betweenness centrality of all nodes.\n",
    "highest_betweenness_node = max(G.nodes, key=betweenness.get)    # Return the node with the highest betweenness centrality.\n",
    "# Output this node with the value of the betweenness centrality.\n",
    "print(highest_betweenness_node) \n",
    "betweenness[highest_betweenness_node]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <li>Closeness centrality:</li>\n",
    "'Closeness centrality' presents how close a node is to other nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closeness = nx.centrality.closeness_centrality(G)   # Return the closeness centrality of all nodes.\n",
    "highest_closeness_node = max(G.nodes, key=closeness.get)    # Return the node with the highest closeness centrality.\n",
    "# Output this node with the value of the closeness centrality.\n",
    "print(highest_closeness_node)\n",
    "closeness[highest_closeness_node]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <li>Degree centrality:</li>\n",
    "Centrality of a node can be computed by how many links to or from the node. The in-degree centrality and out-degree centrality are computed respectively in code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_degree = nx.centrality.in_degree_centrality(G)   # Return the in-degree centrality of all nodes.\n",
    "highest_in_degree_node = max(G.nodes, key=in_degree.get)    # Return the node with the highest in-degree centrality.\n",
    "# Output this node with the value of the in-degree centrality.\n",
    "print(highest_in_degree_node)\n",
    "in_degree[highest_in_degree_node]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Exercise:</strong> please fill out the blank in the below code block to get the node with the highest out-degree centrality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_degree = (____________)   # Return the out-degree centrality of all nodes.\n",
    "highest_out_degree_node = (____________)    # Return the node with the highest out-degree centrality.\n",
    "# Output this node with the value of the out-degree centrality.\n",
    "(____________)\n",
    "(____________)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <li>EigenCentrality:</li>\n",
    "'EigenCentrality' is also a way to measure centrality. It not only, as 'degree centrality', considers the degree of a node, but also considers the degree of the neighbour nodes of the node. For example, if the degree of a node is small, take it for granted, the influence of the node is small. But if the node is connected to a node that has numerous links, the influence of the original node is somehow increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvector = nx.centrality.eigenvector_centrality(G)   # Return the eigenvector centrality of all nodes.\n",
    "highest_eigenvector_node = max(G.nodes, key=eigenvector.get)    # Return the node with the highest eigenvector centrality.\n",
    "# Output the node with the value of the eigenvector centrality.\n",
    "print(highest_eigenvector_node)\n",
    "eigenvector[highest_eigenvector_node]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <li>Page Rank</li>\n",
    "'Page Rank' is a variant of eigenvector centrality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagerank = nx.pagerank(G)   # Return the page rank of all nodes.  \n",
    "highest_pagerank_node = max(G.nodes, key=pagerank.get)    # Return the node with the highest page rank.\n",
    "# Output the node with the value of the page rank.\n",
    "print(highest_pagerank_node)\n",
    "eigenvector[highest_pagerank_node]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Clustering / Community detection\n",
    "A community include nodes that have the same properties. In 'my Instagram network', it could be my classmates at uni, my relatives, or my co-workers. 'Girvan-Newman' algorithm is used to identify communities. The principle of the algorithm is iteratively removing the edge with the highest edge betweenness and comparing the modularity between before and after. The code below demonstrate the process. Finally, the best division of communities is selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def community_detection(G_instagram):\n",
    "    communities_generator = nx.algorithms.community.girvan_newman(G_instagram)\n",
    "    communities_newman = next(communities_generator)\n",
    "    modularity_newman_new = nx.algorithms.community.modularity(G_instagram, communities_newman)\n",
    "\n",
    "    modularity_newman_old = 0.00001\n",
    "    count = 1\n",
    "    while modularity_newman_new > modularity_newman_old:\n",
    "        modularity_newman_old = modularity_newman_new\n",
    "        communities_newman_final = communities_newman\n",
    "        communities_newman = next(communities_generator)\n",
    "        modularity_newman_new = nx.algorithms.community.modularity(G_instagram, communities_newman)\n",
    "        count += 1\n",
    "\n",
    "    partition_newman = {}\n",
    "    for idx, cluster in enumerate(communities_newman_final):\n",
    "        for profile in cluster:\n",
    "            partition_newman[profile] = idx\n",
    "\n",
    "    return partition_newman\n",
    "\n",
    "best_partition_map = community_detection(G)\n",
    "\n",
    "node_colors = [best_partition_map[n] for n in G.nodes()]\n",
    "nx.draw(G, with_labels=False, node_color=node_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Customization\n",
    "MaximPiessen's code provides a way of visualization featuring an interactive graph generated by .json and .js, which is great. An alternative way to improve the visualization is the drawing functionality of Networkx and Matplotlib. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_max_group(partition_map):\n",
    "    from collections import Counter\n",
    "    counter = Counter(partition_map.values())\n",
    "    biggest_group = max(counter, key=counter.get)\n",
    "\n",
    "    new_partition_map = dict()\n",
    "    # Iterate over all the items in dictionary and filter items which has even keys\n",
    "    for (key, value) in partition_map.items():\n",
    "        # Check if key is even then add pair to new dictionary\n",
    "        if value != biggest_group:\n",
    "            new_partition_map[key] = value\n",
    "\n",
    "    labels = {}    \n",
    "    for node in G.nodes():\n",
    "        if node in new_partition_map.keys():\n",
    "            #set the node name as the key and the label as its value \n",
    "            labels[node] = node\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function 'exclude_max_group()' return a collection of nodes that are not in the biggest community, so that only nodes in small communities are labelled in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing with a spring layout.\n",
    "pos = nx.spring_layout(G)\n",
    "# Define the graph size\n",
    "plt.figure(3,figsize=(10,8))\n",
    "# Draw the network\n",
    "nx.draw(G, pos, with_labels=False, \n",
    "            node_color=node_colors, # Change node colors by commnunities\n",
    "            arrows=True,    # Set if the links have arrows\n",
    "            arrowsize=8,    # Set arrow size\n",
    "            node_size=150,  # Set node size\n",
    "            edgecolors=\"gray\",  # Set node border color\n",
    "            edge_color = \"gray\", # Set edge color\n",
    "            linewidths =0.5,    # Set line width of symbol border\n",
    "            width=0.5,          # Set edge line width\n",
    "            font_size=10)       # Set label font size\n",
    "# Draw the labels\n",
    "nx.draw_networkx_labels(G, pos, labels=exclude_max_group(best_partition_map), \n",
    "                            alpha=0.9, # Set transparency of label text\n",
    "                            font_size=16, \n",
    "                            horizontalalignment=\"right\", \n",
    "                            verticalalignment=\"top\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Networkx has a lot of functions to draw graphs. 'nx.draw()' draw a basic network and 'draw_network_labels()' draw labels. Drawing can be customized by multiple parameters. Try to learn the use of each parameter in the sample code. More details can be viewed on https://networkx.org/documentation/stable/reference/drawing.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "Change the size of nodes in small communities in the last graph to 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legal and Ethical Consideration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping and using data from social media platforms may be illegal. Before obtaining data, highly recommend reading the Terms of Use and referring to the robots.txt files of your target websites, otherwise you may be in violation of the terms.<br>\n",
    "Be cautious of the use of data. Avoid the breach of copyright or privacy because of publishing the scraped data. Scam and phishing are prohibited. Jurisdictions in different countries and regions should be taken into consideration too."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "45a851a8e049304e8d8fc9276f397ed5699faa42a654317800ed71714fc34a6c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
